# üåü Hi, I'm **Muhammad Dwiva Arya Erlangga**

### iOS Engineer ‚Ä¢ Machine Learning Developer ‚Ä¢ App-Store Publisher ‚Ä¢ Apple Developer Academy Graduate

üìç **Bali, Indonesia**
üì´ **[dwiva432@gmail.com](mailto:dwiva432@gmail.com)**
üîó **LinkedIn:** [https://linkedin.com/in/mdaryaerlangga](https://linkedin.com/in/mdaryaerlangga)
üêô **GitHub:** [https://github.com/ary3141](https://github.com/ary3141)

I design and build intelligent iOS applications backed by machine learning and robust backend services. My passion lies in creating real-world, user-centric products that combine **on-device ML**, **real-time audio/vision processing**, and intuitive **user interfaces**. I‚Äôve published apps on the App Store, contributed to ML and backend pipelines, and collaborated with cross-disciplinary teams to deliver production-ready solutions.

---

# üõ†Ô∏è Tech Stack & Expertise

* **Languages:** Swift ¬∑ Python ¬∑ JavaScript
* **iOS / Mobile:** SwiftUI, SwiftData, UIKit, Combine, AVFoundation, CoreML, CoreData, MVVM architecture
* **Machine Learning:** TensorFlow, scikit-learn, CoreML conversion (PyTorch ‚Üí CoreML), on-device inference, data preprocessing & model tuning
* **Backend / APIs:** Flask, REST APIs, WebSockets, Python backend services
* **Tools & Workflow:** Git/GitHub, CocoaPods, Postman, Xcode, App Store Connect, TestFlight

---

# üöÄ Projects & Highlights

These are selected projects that showcase my skills in mobile engineering, ML integration, backend development, and cross-platform collaboration.

---

## üì± Mobile & iOS Applications

### **Lulla ‚Äî Emotional Voice Communication App**

**AppStore:** [LullaTalk](https://apps.apple.com/my/app/lullatalk/id6751548919?l=ms)
**Repo:** [Lulla](https://github.com/ary3141/Lulla)
A mobile app designed to help parents and children express emotions via voice.

* Built the **entire UI/UX with SwiftUI** and voice-interactions using **AVFoundation**.
* Implemented **on-device secure storage** of emotional logs with **SwiftData** ‚Äî ensures privacy and offline availability.
* Designed responsive, real-time UI feedback for emotional expression.
* **Impact:** Enabled intimate emotional communication through voice and intuitive UX, offering an accessible communication tool.

---

### **Bamboom ‚Äî Gesture-Based Fitness Tracker**

**Repo:** [bamboom](https://github.com/SaputraUta/bamboom)
A fitness app that tracks user gestures and exercises via motion sensors and ML classification.

* Captured motion data using **Core Motion**, processed in Python, and trained a **KNN classifier with ~90% accuracy**.
* Built iOS front-end with SwiftUI; planning integration of **CoreML** for on-device inference.
* Demonstrated how mobile + ML + sensor data can combine to produce lightweight fitness apps.

---

### **OGMO ‚Äî Live Transcription & Captioning**

**App Store: ** [OGMO](https://apps.apple.com/my/app/ogmo-live-class-captions/id6755096384?l=ms)
**Repo:** [OGMO](https://github.com/Wentao-tao/Unmute)
A real-time transcription app designed for classrooms or lectures to assist hearing-impaired users or note-taking.

* Built audio capture pipeline using **AVAudioEngine**.
* Integrated **Soniox transcription backend** for speech-to-text, while experimenting with **Apple Intelligence diarization**.
* Worked on WebSocket architecture for custom ML-based live transcription stream (in development).
* Showcases ability to integrate streaming, audio processing, and backend-powered ML in mobile apps.

---

## **ARound ‚Äî Augmented Reality Object Detection App**

**App Store:** [AroundADA](https://apps.apple.com/my/app/around-ada/id6746779581?l=ms)
**Repository:** [Repo](https://github.com/Winfr1th/C2-RnB)

ARound is an augmented-reality app that allows users to **identify objects around them in real time** using their device camera. Built as part of the Apple Developer Academy program, it combines **AR, machine learning, and CoreML inference** into an immersive mobile experience.

### **What I built**

* Implemented the **on-device machine learning pipeline** (YOLOv11 ‚Üí CoreML)
* Processed and optimized datasets, including image preprocessing and model tuning
* Achieved **~97% model accuracy** and optimized inference speed to run smoothly on-device
* Designed the SwiftUI interface for object detection and AR projection
* Built the Python ‚Üí CoreML conversion pipeline and testing scripts
* Worked on the real-time detection flow (camera input ‚Üí model ‚Üí AR overlay)

### **Tech Used**

SwiftUI ‚Ä¢ CoreML ‚Ä¢ Vision ‚Ä¢ Python (model preprocessing) ‚Ä¢ ARKit (if used) ‚Ä¢ YOLOv11 ‚Üí CoreML conversion

### **Impact**

Delivered an accessible and intuitive AR experience that allows users to understand their environment through real-time object detection ‚Äî with fast inference and a clean UI.

---

## ü§ñ Machine Learning & AI Projects

### **AI-Exploration ‚Äî ML Research Sandbox**

**Repo:** [Ai-exploration](https://github.com/ary3141/Ai-exploration)
A collection of ML experiments: classification, vision tasks, data preprocessing, and prototyping.

* Experimented with various algorithms ‚Äî vision models, data pipelines, model tuning.
* Useful demonstration of foundational ML knowledge and hands-on data work.

### **Tubes Pengantar Kecerdasan Buatan ‚Äî Academic AI Project**

**Repo:** [TubesPengantarKecerdasanBuatan](https://github.com/ary3141/TubesPengantarKecerdasanBuatan)
Completed as part of university coursework ‚Äî includes algorithm implementations, heuristic models, and documented experiments.
Demonstrates strong academic foundation in AI theory, problem solving, and code documentation.

---

## üß∞ Backend / Full-Stack & Web Projects

## **ABP News Platform ‚Äî Multiplatform News App (Mobile + Web + Backend API)**

üì± **Mobile App:** Cross-platform news reader (Android/iOS via Flutter or similar)
üåê **Web App:** Interactive online news portal
üîß **Backend API:** Flask server for news aggregation + Gemini summarization
üìÇ **Repo (Backend):** [https://github.com/ary3141/backendTubesABP](https://github.com/ary3141/backendTubesABP)
üìÇ **Repo (Web):** [https://github.com/sagungputri/Tubes-ABP-WEB](https://github.com/sagungputri/Tubes-ABP-WEB)

A **multi-platform news ecosystem** built for university's Application-Based Programming course.
It includes a mobile app, a web interface, and a Flask backend that fetches live news, processes it, and summarizes it using **Google Gemini**.

### **What I built**

* Developed the **backend API** using Flask

  * Fetches news articles from external sources
  * Generates **AI-powered summaries** using Gemini
  * Provides structured JSON endpoints for both mobile and web clients

* Contributed to the **web front-end**

  * Implemented UI components
  * Integrated API endpoints for displaying news + summaries
  * Ensured smooth user experience and responsiveness

* Contributed to the **mobile app**

  * Designed UI flows
  * Integrated backend APIs
  * Worked on cross-platform architecture

### **Tech Used**

Flask ‚Ä¢ REST APIs ‚Ä¢ Gemini API ‚Ä¢ HTML/CSS/JS ‚Ä¢ Flutter
Cross-platform mobile integration ‚Ä¢ JSON data formatting

### **Impact**

Delivered a **full ecosystem**‚Äîbackend, web app, and mobile app‚Äîcapable of automatically fetching news, summarizing content using AI, and presenting it in a clean, unified user experience across multiple platforms.

### **ToDo App ‚Äî Basic CRUD Web Application**

**Repo:** [todo-app](https://github.com/alipw/todo-app)
A simple web application that implements CRUD operations ‚Äî foundational project showing web fundamentals and practical coding practice.

---

## üß† Algorithms, Coursework & Utility Projects

### **CookingSteakProblem ‚Äî Algorithm Challenge**

**Repo:** [CookingSteakProblem](https://github.com/ary3141/CookingSteakProblem)
Solves algorithmic problem using efficient Python code ‚Äî demonstrates problem-solving, algorithmic thinking, and coding skill.

### **MultiThread ‚Äî Networking & Concurrency**

**Repo:** [MultiThread](https://github.com/ary3141/MultiThread)
Demonstrates multithreading, concurrent client-server architecture ‚Äî good baseline for networked applications and backend systems.

---

# Featured Full-Stack + ML + Mobile System

## **GoVision ‚Äî Visual Assistance System (iOS + Backend + ML)**

A complete end-to-end system combining mobile app, backend, and ML model server for accessibility.

### GoVision Frontend

**Repo:** [govision_app](https://github.com/dikaizm/govision_app.git)

* SwiftUI-based mobile app capturing camera/video frames in real time
* Sends frames to backend for ML inference ‚Äî designed for accessibility and assistive vision use cases

### GoVision Backend API

**Repo:** [govision_backend](https://github.com/dikaizm/govision_backend.git)

* Flask / FastAPI backend that accepts image input, runs detection, and returns structured results to client

### GoVision Model Server

**Repo:** [govision_model](https://github.com/dikaizm/govision_model.git)

* ML model loading + inference pipeline (object detection/classification)
* Integrated with backend to serve real-time vision inference results

*This project illustrates my capability to design and build full-stack, ML-powered mobile systems ‚Äî from camera input to inference to UI output.*
